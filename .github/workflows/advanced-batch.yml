name: Advanced Batch Processing

on:
  schedule:
    # 稼働率計算: 毎日日本時間12時（UTC 3時）
    - cron: '0 3 * * *'
    # 稼働状況取得: 30分ごと
    - cron: '*/30 * * * *'
    # ヘルスチェック: 15分ごと
    - cron: '*/15 * * * *'
    # クリーンアップ: 毎日日本時間午前2時（UTC 17時前日）
    - cron: '0 17 * * *'
  workflow_dispatch:
    inputs:
      job_type:
        description: 'Job type to run'
        required: true
        default: 'status-collection'
        type: choice
        options:
        - status-collection
        - working-rate-calculation
        - health-check
        - cleanup
        - debug-html
      environment:
        description: 'Environment'
        required: true
        default: 'production'
        type: choice
        options:
        - development
        - production

jobs:
  batch-job:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    strategy:
      fail-fast: false
      matrix:
        include:
          - job: status-collection
            timeout: 20
          - job: working-rate-calculation
            timeout: 30
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
        cache-dependency-path: 'batch/requirements.txt'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y postgresql-client
    
    - name: Install Python dependencies
      run: |
        cd batch
        pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Setup configuration files
      run: |
        mkdir -p config logs batch/logs
        
        # Create secret.yml
        cat > config/secret.yml << EOF
        database:
          url: "${{ secrets.DATABASE_URL }}"
          password: "${{ secrets.DB_PASSWORD }}"
        auth:
          secret_key: "${{ secrets.AUTH_SECRET_KEY }}"
        x_api:
          bearer_token: "${{ secrets.X_BEARER_TOKEN }}"
          api_key: "${{ secrets.X_API_KEY }}"
          api_secret: "${{ secrets.X_API_SECRET }}"
          access_token: "${{ secrets.X_ACCESS_TOKEN }}"
          access_token_secret: "${{ secrets.X_ACCESS_TOKEN_SECRET }}"
        EOF
        
        # Verify config files exist
        ls -la config/
        echo "Config files created successfully"
    
    - name: Database connectivity test
      run: |
        cd batch
        python -c "
        from utils.config import get_database_config
        from core.database import get_database_engine
        try:
            config = get_database_config()
            engine = get_database_engine(config)
            with engine.connect() as conn:
                result = conn.execute('SELECT 1')
                print('Database connection successful')
        except Exception as e:
            print(f'Database connection failed: {e}')
            exit(1)
        "
    
    - name: Execute batch job
      timeout-minutes: ${{ matrix.timeout }}
      run: |
        cd batch
        
        # Set environment based on input or default to production
        export ENVIRONMENT="${{ github.event.inputs.environment || 'production' }}"
        
        # Determine job type
        JOB_TYPE="${{ github.event.inputs.job_type || matrix.job }}"
        
        echo "Executing job: $JOB_TYPE in environment: $ENVIRONMENT"
        
        case "$JOB_TYPE" in
          "status-collection")
            python main.py status-collection --verbose
            ;;
          "working-rate-calculation")
            python main.py working-rate-calculation --verbose
            ;;
          "health-check")
            python main.py health-check
            ;;
          "cleanup")
            python main.py cleanup --days 30
            ;;
          "debug-html")
            # For debug, use a sample file if available
            if [ -f "data/sample.html" ]; then
              python main.py debug-html --local-file "data/sample.html"
            else
              echo "No sample HTML file found, skipping debug-html"
            fi
            ;;
          *)
            echo "Unknown job type: $JOB_TYPE"
            exit 1
            ;;
        esac
    
    - name: Check job results
      if: always()
      run: |
        cd batch
        
        # Check if logs directory exists and has content
        if [ -d "logs" ] && [ "$(ls -A logs)" ]; then
          echo "=== Latest log files ==="
          ls -la logs/
          
          echo "=== Recent log entries ==="
          find logs -name "*.log" -type f -exec tail -20 {} \; 2>/dev/null || true
        else
          echo "No log files found"
        fi
        
        # Check for any error indicators
        if find logs -name "*.log" -type f -exec grep -l "ERROR\|CRITICAL" {} \; 2>/dev/null | head -1; then
          echo "⚠️ Errors detected in log files"
          exit 1
        else
          echo "✅ No critical errors detected"
        fi
    
    - name: Upload logs and artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: batch-logs-${{ matrix.job || github.event.inputs.job_type }}-${{ github.run_number }}
        path: |
          batch/logs/
          config/config.yml
        retention-days: 7
    
    - name: Notify on failure
      if: failure()
      run: |
        echo "🚨 Batch job failed: ${{ matrix.job || github.event.inputs.job_type }}"
        echo "Check the uploaded artifacts for detailed logs"
        
  # 並行実行ジョブ（手動実行時のみ）
  parallel-execution:
    if: github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        job: [status-collection, working-rate-calculation]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        cd batch
        pip install -r requirements.txt
    
    - name: Setup configuration
      run: |
        mkdir -p config
        cat > config/secret.yml << EOF
        database:
          url: "${{ secrets.DATABASE_URL }}"
          password: "${{ secrets.DB_PASSWORD }}"
        auth:
          secret_key: "${{ secrets.AUTH_SECRET_KEY }}"
        x_api:
          bearer_token: "${{ secrets.X_BEARER_TOKEN }}"
          api_key: "${{ secrets.X_API_KEY }}"
          api_secret: "${{ secrets.X_API_SECRET }}"
          access_token: "${{ secrets.X_ACCESS_TOKEN }}"
          access_token_secret: "${{ secrets.X_ACCESS_TOKEN_SECRET }}"
        EOF
    
    - name: Execute parallel job
      run: |
        cd batch
        python main.py ${{ matrix.job }} --parallel
    
    - name: Upload parallel job logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: parallel-batch-logs-${{ matrix.job }}
        path: batch/logs/