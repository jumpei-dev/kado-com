#!/usr/bin/env python3
"""
ç°¡å˜ãªãƒ—ãƒ­ã‚­ã‚·ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ
"""

import asyncio
import aiohttp
import random
import sys
from pathlib import Path

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent))

from utils.config import get_scraping_config

async def test_basic_scraping():
    """åŸºæœ¬çš„ãªã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ†ã‚¹ãƒˆï¼ˆãƒ—ãƒ­ã‚­ã‚·ãªã—ï¼‰"""
    print("ğŸš€ åŸºæœ¬çš„ãªã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    config = get_scraping_config()
    print(f"ğŸ“‹ è¨­å®š: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ={config['timeout']}ç§’, ãƒªãƒˆãƒ©ã‚¤={config['retry_attempts']}å›")
    
    # IPã‚¢ãƒ‰ãƒ¬ã‚¹ç¢ºèªç”¨URL
    test_urls = [
        'http://httpbin.org/ip',
        'http://httpbin.org/user-agent',
        'http://httpbin.org/headers'
    ]
    
    timeout = aiohttp.ClientTimeout(total=config['timeout'])
    
    async with aiohttp.ClientSession(timeout=timeout) as session:
        for i, url in enumerate(test_urls):
            print(f"\n--- ãƒ†ã‚¹ãƒˆ {i+1}: {url} ---")
            
            try:
                # User-Agentã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
                user_agent = random.choice(config['user_agents'])
                headers = {
                    'User-Agent': user_agent,
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    'Accept-Language': 'ja,en-US;q=0.7,en;q=0.3',
                    'Accept-Encoding': 'gzip, deflate',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1'
                }
                
                print(f"ğŸ”„ User-Agent: {user_agent[:50]}...")
                
                async with session.get(url, headers=headers) as response:
                    if response.status == 200:
                        content = await response.text()
                        print(f"âœ… æˆåŠŸ (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status})")
                        
                        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹ã®ä¸€éƒ¨ã‚’è¡¨ç¤º
                        if len(content) > 200:
                            print(f"ğŸ“„ ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {content[:200]}...")
                        else:
                            print(f"ğŸ“„ ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {content}")
                    else:
                        print(f"âŒ å¤±æ•— (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status})")
                        
            except asyncio.TimeoutError:
                print("â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼")
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”
            delay = random.uniform(config['min_delay'], config['max_delay'])
            print(f"â±ï¸ {delay:.1f}ç§’å¾…æ©Ÿä¸­...")
            await asyncio.sleep(delay)

async def test_with_different_settings():
    """ç•°ãªã‚‹è¨­å®šã§ã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ”§ è¨­å®šå¤‰æ›´ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ã‚ˆã‚Šä¿å®ˆçš„ãªè¨­å®š
    conservative_config = {
        'timeout': 15,
        'user_agents': [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        ],
        'min_delay': 2.0,
        'max_delay': 5.0,
        'retry_attempts': 2
    }
    
    print(f"ğŸ“‹ ä¿å®ˆçš„è¨­å®š: å¾…æ©Ÿæ™‚é–“={conservative_config['min_delay']}-{conservative_config['max_delay']}ç§’")
    
    timeout = aiohttp.ClientTimeout(total=conservative_config['timeout'])
    
    async with aiohttp.ClientSession(timeout=timeout) as session:
        url = 'http://httpbin.org/delay/1'  # 1ç§’é…å»¶ã®ã‚ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        
        for attempt in range(3):
            print(f"\n--- è©¦è¡Œ {attempt + 1} ---")
            
            try:
                user_agent = random.choice(conservative_config['user_agents'])
                headers = {'User-Agent': user_agent}
                
                start_time = asyncio.get_event_loop().time()
                async with session.get(url, headers=headers) as response:
                    end_time = asyncio.get_event_loop().time()
                    
                    if response.status == 200:
                        print(f"âœ… æˆåŠŸ (å¿œç­”æ™‚é–“: {end_time - start_time:.2f}ç§’)")
                    else:
                        print(f"âŒ å¤±æ•— (ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {response.status})")
                        
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            
            # é•·ã‚ã®å¾…æ©Ÿæ™‚é–“
            delay = random.uniform(conservative_config['min_delay'], conservative_config['max_delay'])
            print(f"â±ï¸ {delay:.1f}ç§’å¾…æ©Ÿä¸­...")
            await asyncio.sleep(delay)

async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("="*50)
    print("ğŸŒ ãƒ—ãƒ­ã‚­ã‚·ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½ ç°¡æ˜“ãƒ†ã‚¹ãƒˆ")
    print("="*50)
    
    try:
        await test_basic_scraping()
        await test_with_different_settings()
        
        print("\nğŸ ãƒ†ã‚¹ãƒˆå®Œäº†")
        print("\nğŸ“ çµæœ:")
        print("- åŸºæœ¬çš„ãªHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯æ­£å¸¸ã«å‹•ä½œ")
        print("- User-Agentãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¯æ©Ÿèƒ½")
        print("- ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”åˆ¶å¾¡ã¯æ©Ÿèƒ½")
        print("\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("- å®Ÿéš›ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã‚µã‚¤ãƒˆã§ãƒ†ã‚¹ãƒˆ")
        print("- ãƒ—ãƒ­ã‚­ã‚·ã‚µãƒ¼ãƒ“ã‚¹ã®å°å…¥ã‚’æ¤œè¨")
        print("- ã‚ˆã‚Šé«˜åº¦ãªã‚¢ã‚¯ã‚»ã‚¹æ‹’å¦å¯¾ç­–ã®å®Ÿè£…")
        
    except Exception as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())