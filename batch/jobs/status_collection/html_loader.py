"""
HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ»ãƒªãƒ¢ãƒ¼ãƒˆå¯¾å¿œï¼‰

ãƒ­ãƒ¼ã‚«ãƒ«HTMLãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨Seleniumã«ã‚ˆã‚‹ãƒªãƒ¢ãƒ¼ãƒˆå–å¾—ã‚’ç®¡ç†
"""

import asyncio
import concurrent.futures
from datetime import datetime
from pathlib import Path
from typing import Optional

try:
    from .webdriver_manager import WebDriverManager
except ImportError:
    try:
        from webdriver_manager import WebDriverManager
    except ImportError as e:
        print(f"WebDriverManager import failed: {e}")
        WebDriverManager = None

try:
    from ..utils.logging_utils import get_logger
except ImportError:
    try:
        from utils.logging_utils import get_logger
    except ImportError:
        def get_logger(name):
            import logging
            return logging.getLogger(name)

logger = get_logger(__name__)


class HTMLLoader:
    """HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®èª­ã¿è¾¼ã¿å‡¦ç†"""
    
    def __init__(self, use_local_html: bool = False, specific_file: Optional[str] = None):
        self.use_local_html = use_local_html
        self.specific_file = specific_file
    
    async def load_html_content(
        self, 
        business_name: str, 
        business_id: str, 
        url: Optional[str] = None,
        local_file: Optional[str] = None
    ) -> tuple[str, datetime]:
        """HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ãƒ»ãƒªãƒ¢ãƒ¼ãƒˆå¯¾å¿œï¼‰"""
        if self.use_local_html:
            # å„ªå…ˆé †ä½: 1. local_fileå¼•æ•°, 2. ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹è¨­å®š, 3. è‡ªå‹•æ¤œç´¢
            file_to_load = local_file or self.specific_file
            if file_to_load:
                return await self._load_specific_html_file(file_to_load)
            else:
                return await self._load_local_html_with_timestamp(business_name, business_id)
        else:
            if not url:
                raise ValueError("ãƒªãƒ¢ãƒ¼ãƒˆå–å¾—ã«ã¯URLãŒå¿…è¦ã§ã™")
            content = await self._load_remote_html(url)
            # ãƒªãƒ¢ãƒ¼ãƒˆå–å¾—ã®å ´åˆã¯ç¾åœ¨æ™‚åˆ»ã‚’è¿”ã™
            return content, datetime.now()
    
    async def _load_specific_html_file(self, filename: str) -> tuple[str, datetime]:
        """æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«åã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        try:
            # data/raw_html/cityhaven/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®æŒ‡å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            base_dir = Path(__file__).parent.parent.parent.parent / "data" / "raw_html" / "cityhaven"
            html_file = base_dir / filename
            
            if not html_file.exists():
                logger.error(f"æŒ‡å®šã•ã‚ŒãŸHTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {html_file}")
                return "", datetime.now()
            
            logger.info(f"ğŸ“ æŒ‡å®šã•ã‚ŒãŸHTMLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­: {filename}")
            with open(html_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›´æ™‚åˆ»ã‚’å–å¾—
            file_mtime = html_file.stat().st_mtime
            file_datetime = datetime.fromtimestamp(file_mtime)
            
            logger.info(f"âœ“ HTMLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {len(content)} æ–‡å­—, å–å¾—æ™‚åˆ»: {file_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
            return content, file_datetime
            
        except Exception as e:
            logger.error(f"æŒ‡å®šHTMLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return "", datetime.now()
    
    async def _load_local_html_with_timestamp(self, business_name: str, business_id: str) -> tuple[str, datetime]:
        """ãƒ­ãƒ¼ã‚«ãƒ«HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨å–å¾—æ™‚åˆ»ã‚’èª­ã¿è¾¼ã‚€ï¼ˆé–‹ç™ºç”¨ï¼‰"""
        try:
            # data/raw_html/cityhaven/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ç´¢
            base_dir = Path(__file__).parent.parent.parent.parent / "data" / "raw_html" / "cityhaven"
            
            if not base_dir.exists():
                logger.warning(f"ãƒ­ãƒ¼ã‚«ãƒ«HTMLãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {base_dir}")
                return "", datetime.now()
            
            # åº—èˆ—åã¾ãŸã¯business_idã§HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            search_patterns = [
                f"äººå¦»åŸ*.html",  # äººå¦»åŸã‚’å„ªå…ˆ
                f"{business_name}_*.html",
                f"*{business_name}*.html",
                f"{business_id}_*.html",
                f"*{business_id}*.html"
            ]
            
            html_file = None
            for pattern in search_patterns:
                matches = list(base_dir.glob(pattern))
                if matches:
                    html_file = matches[0]  # æœ€åˆã®ãƒãƒƒãƒã‚’ä½¿ç”¨
                    logger.info(f"HTMLãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {pattern} -> {html_file.name}")
                    break
            
            if not html_file:
                # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒã—ãªã„å ´åˆã€å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚¹ãƒˆã—ã¦æœ€æ–°ã‚’é¸æŠ
                html_files = list(base_dir.glob("*.html"))
                if html_files:
                    html_file = max(html_files, key=lambda x: x.stat().st_mtime)
                    logger.info(f"ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãªã—ã€æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨: {html_file.name}")
                else:
                    logger.warning(f"ãƒ­ãƒ¼ã‚«ãƒ«HTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {base_dir}")
                    return "", datetime.now()
            
            # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            logger.info(f"ğŸ“ HTMLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­: {html_file.name}")
            with open(html_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›´æ™‚åˆ»ã‚’å–å¾—ï¼ˆHTMLãŒå®Ÿéš›ã«å–å¾—ã•ã‚ŒãŸæ™‚åˆ»ï¼‰
            file_mtime = html_file.stat().st_mtime
            file_datetime = datetime.fromtimestamp(file_mtime)
            
            logger.info(f"âœ“ HTMLãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {len(content)} æ–‡å­—, å–å¾—æ™‚åˆ»: {file_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
            return content, file_datetime
            
        except Exception as e:
            logger.error(f"ãƒ­ãƒ¼ã‚«ãƒ«HTMLèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return "", datetime.now()
    
    async def _load_remote_html(self, url: str) -> str:
        """Seleniumã‚’ä½¿ã£ã¦ãƒªãƒ¢ãƒ¼ãƒˆHTMLã‚’å–å¾—"""
        def _sync_scrape():
            """åŒæœŸçš„ãªSeleniumã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†"""
            webdriver_manager = None
            try:
                print("  ğŸŒ WebDriverManagerã‚’ä½œæˆä¸­...")
                webdriver_manager = WebDriverManager()
                print("  âœ“ WebDriverManagerä½œæˆå®Œäº†")
                
                print("  ğŸ“„ ãƒšãƒ¼ã‚¸ã‚½ãƒ¼ã‚¹ã‚’å–å¾—ä¸­...")
                page_source = webdriver_manager.get_page_source(url)
                print("  âœ“ ãƒšãƒ¼ã‚¸ã‚½ãƒ¼ã‚¹å–å¾—å‡¦ç†å®Œäº†")
                
                return page_source
            except Exception as e:
                print(f"  âŒ _sync_scrapeã‚¨ãƒ©ãƒ¼: {e}")
                raise
            finally:
                print("  ğŸ”„ WebDriverManagerã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
                if webdriver_manager:
                    webdriver_manager.close()
                print("  âœ“ WebDriverManagerã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")
        
        # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§Seleniumã‚’å®Ÿè¡Œ
        loop = asyncio.get_event_loop()
        with concurrent.futures.ThreadPoolExecutor() as executor:
            page_source = await loop.run_in_executor(executor, _sync_scrape)
        
        return page_source
