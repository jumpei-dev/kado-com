"""
Cityheavenå°‚ç”¨ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æˆ¦ç•¥

Cityheavenã‚µã‚¤ãƒˆã®æŒ‡ç¤ºæ›¸æº–æ‹ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†
"""

import aiohttp
from abc import ABC, abstractmethod
from bs4 import BeautifulSoup
from typing import Dict, List, Any, Optional
from datetime import datetime
import json

from .html_loader import HTMLLoader
from .cityheaven_parsers import CityheavenParserFactory

try:
    from ..utils.datetime_utils import get_current_jst_datetime
except ImportError:
    def get_current_jst_datetime():
        from datetime import datetime
        return datetime.now()

try:
    from ..utils.logging_utils import get_logger
except ImportError:
    def get_logger(name):
        import logging
        return logging.getLogger(name)

logger = get_logger(__name__)


class ScrapingStrategy(ABC):
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æˆ¦ç•¥ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    @abstractmethod
    async def scrape_working_status(self, session: aiohttp.ClientSession, business: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç¨¼åƒã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’åé›†ã™ã‚‹æŠ½è±¡ãƒ¡ã‚½ãƒƒãƒ‰"""
        pass


class CityheavenStrategy(ScrapingStrategy):
    """Cityheavenã‚µã‚¤ãƒˆç”¨ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æˆ¦ç•¥ï¼ˆSeleniumä½¿ç”¨ï¼‰"""
    
    def __init__(self, use_local_html: bool = False):
        """
        åˆæœŸåŒ–
        
        Args:
            use_local_html: ãƒ­ãƒ¼ã‚«ãƒ«HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹ï¼ˆé–‹ç™ºç”¨ï¼‰
        """
        self.use_local_html = use_local_html
        self.html_loader = HTMLLoader(use_local_html)
        
        if use_local_html:
            logger.info("ğŸ”§ é–‹ç™ºãƒ¢ãƒ¼ãƒ‰: ãƒ­ãƒ¼ã‚«ãƒ«HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™")
        else:
            logger.info("ğŸŒ æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰: Seleniumã§ãƒ©ã‚¤ãƒ–ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã¾ã™")
    
    async def scrape_working_status(self, session: aiohttp.ClientSession, business: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Cityheavenã‹ã‚‰ç¨¼åƒã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’åé›†ï¼ˆæŒ‡ç¤ºæ›¸æº–æ‹ ï¼‰"""
        cast_list = []
        
        # DBã‹ã‚‰å„ç¨®æƒ…å ±ã‚’å–å¾—ï¼ˆä¸¡æ–¹ã®ã‚­ãƒ¼åã«å¯¾å¿œï¼‰
        business_id = business.get("business_id") or business.get("Business ID")
        url = business.get("URL")
        business_name = business.get("name") or business.get("Name", business_id)
        media = business.get("media", "cityhaven")
        cast_type = business.get("cast_type", "a")
        working_type = business.get("working_type", "a")
        shift_type = business.get("shift_type", "a")
        
        if not url or not business_id:
            logger.warning(f"å¿…è¦ãªæƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™: business_id={business_id}, url={url}")
            return cast_list
        
        try:
            logger.info(f"ğŸ¯ Cityheavenãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹: {business_id} (media={media}, cast={cast_type}, working={working_type}, shift={shift_type})")
            
            # HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
            page_source = await self.html_loader.load_html_content(business_name, business_id, url)
            if not page_source:
                logger.warning(f"HTMLã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å–å¾—ã«å¤±æ•—: {business_name}")
                return cast_list
            
            collection_method = "ãƒ­ãƒ¼ã‚«ãƒ«HTML" if self.use_local_html else "Selenium"
            logger.info(f"ğŸ“ {collection_method}ã§ã®HTMLå–å¾—æˆåŠŸ: {business_name} ({len(page_source)} æ–‡å­—)")
            
            # BeautifulSoupã§ãƒ‘ãƒ¼ã‚¹
            soup = BeautifulSoup(page_source, 'html.parser')
            
            # æŒ‡ç¤ºæ›¸æº–æ‹ ã®typeåˆ¥ãƒ‘ãƒ¼ã‚¹å‡¦ç†
            cast_list = await self._parse_cityhaven_data(soup, business_id, cast_type, working_type, shift_type)
            
            logger.info(f"ğŸ¯ {collection_method}ã§ã®åé›†å®Œäº†: {business_name}, {len(cast_list)}ä»¶")
                
        except Exception as e:
            collection_method = "ãƒ­ãƒ¼ã‚«ãƒ«HTML" if self.use_local_html else "Selenium"
            logger.error(f"âŒ {collection_method}ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼ {business_id}: {str(e)}")
            import traceback
            logger.error(f"è©³ç´°ã‚¨ãƒ©ãƒ¼: {traceback.format_exc()}")
            
        return cast_list
    
    async def _parse_cityhaven_data(self, soup: BeautifulSoup, business_id: str, cast_type: str, working_type: str, shift_type: str) -> List[Dict[str, Any]]:
        """
        æŒ‡ç¤ºæ›¸æº–æ‹ ã®Cityheavenãƒ‡ãƒ¼ã‚¿è§£æ
        
        æŒ‡ç¤ºæ›¸ã®æ¡ä»¶:
        - mediaãŒcityheavenã€cast_typeã€shift_typeã€working_typeãŒãã‚Œãã‚Œaã®ã¨ã
        - ClassåãŒ"sugunavi_wrapper"ã®divè¦ç´ ã§sugunaviboxã‚’å«ã‚€ã‚‚ã®ãŒå¯¾è±¡
        """
        cast_list = []
        current_time = get_current_jst_datetime()
        
        try:
            logger.info(f"æŒ‡ç¤ºæ›¸æº–æ‹ è§£æé–‹å§‹: business_id={business_id}, cast_type={cast_type}, working_type={working_type}, shift_type={shift_type}")
            
            # ãƒ‡ãƒãƒƒã‚°: HTMLã®å†…å®¹ã‚’å°‘ã—ç¢ºèª
            title = soup.find('title')
            if title:
                logger.info(f"ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«: {title.get_text().strip()}")
            
            # ãƒ‘ãƒ¼ã‚µãƒ¼ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ã‚’ä½¿ç”¨
            parser = CityheavenParserFactory.get_parser(cast_type, working_type, shift_type)
            cast_list = await parser.parse_cast_data(soup, business_id, current_time)
                
        except Exception as e:
            logger.error(f"Cityheavenè§£æã‚¨ãƒ©ãƒ¼ {business_id}: {str(e)}")
            
        return cast_list
